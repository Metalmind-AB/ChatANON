# ChatANON Backend Configuration Template
# Copy this file to .env and update with your values

# Server Configuration
HOST=0.0.0.0
PORT=8081
LOG_LEVEL=info
RELOAD=true

# Ollama Configuration
# Update OLLAMA_BASE_URL if your Ollama instance runs on a different host/port
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_DEFAULT_MODEL=qwen3:8b
OLLAMA_FAST_MODEL=qwen3:8b
OLLAMA_QUALITY_MODEL=qwen3:32b
OLLAMA_TIMEOUT=180
OLLAMA_MAX_RETRIES=3

# Processing Configuration
DEFAULT_CHUNK_SIZE=1000
DEFAULT_CHUNK_OVERLAP=0
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=300

# Security Configuration
FRONTEND_PORT=3002
CORS_ALLOW_ALL=true
# Add additional CORS origins as needed, comma-separated
CORS_ADDITIONAL_ORIGINS=http://localhost:3000,http://localhost:3001
API_KEY_REQUIRED=false
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# Features Configuration
ENABLE_REASONING=true
ENABLE_WEBSOCKETS=true
ENABLE_STREAMING=true
ENABLE_HEALTH_CHECK=true

# Storage Configuration (optional)
ENABLE_AUDIT_LOG=false
AUDIT_LOG_PATH=./logs/audit.log
CACHE_ENABLED=false
CACHE_TTL=3600

# Debug Configuration
DEBUG_MODE=false
VERBOSE_LOGGING=false
PROFILE_PERFORMANCE=false